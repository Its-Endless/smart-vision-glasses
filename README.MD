# **Smart Vision Glasses â€“ An AI-Powered Assistive System for the Visually Impaired**

Smart Vision Glasses is an AI-driven assistive technology designed to empower visually impaired individuals with real-time understanding of their surroundings.
This system combines **computer vision**, **speech interaction**, and **multimodal AI features** to create an accessible, reliable, and low-cost solution.

The project currently runs as a **software prototype on a laptop**, with future plans to integrate it into lightweight wearable smart glasses.

---

## ğŸŒŸ **Features**

### âœ… **1. Object Detection (YOLOv5su)**

* Detects people, vehicles, and obstacles in real time.
* Announces object name, direction, and approximate distance.
* Helps the user stay aware of their surroundings.

### âœ… **2. Face Recognition (On-Device Training)**

* Detects and recognizes known individuals.
* Allows users to **scan new faces** via voice and trains instantly on local device.
* Works fully offline using LBPH.

### âœ… **3. Text Reader (OCR â€“ EasyOCR)**

* Reads printed text from signboards, documents, labels, menus, etc.
* Works offline and speaks text aloud in real time.
* Uses threaded processing for smooth performance.

### âœ… **4. Emotion Detection**

* Identifies basic facial emotions (happy, sad, neutral).
* Provides social context cues for visually impaired users.

### âœ… **5. GPS Mode (Prototype)**

* Basic location and direction support.
* Future integration with mobile app for full navigation.

### ğŸ¤ **Hands-Free Voice Control**

* Hotword detection: **â€œHey Visionâ€**
* Commands like:

  * â€œTurn on object detectionâ€
  * â€œOpen text readerâ€
  * â€œScan new faceâ€
  * â€œStop face detectionâ€
* Voice recognition with keyboard fallback for noisy environments.

---

## ğŸ§± **System Architecture**

```
main.py 
   â†³ mode_manager.py
       â†³ modes/
           â€¢ object_detection.py
           â€¢ face_detection.py
           â€¢ text_reader.py
           â€¢ emotion_detection.py
           â€¢ gps_mode.py
       â†³ utils/
           â€¢ speech_engine.py
           â€¢ camera_stream.py
           â€¢ audio_alerts.py
           â€¢ ocr_utils.py
```

Each mode is **independent**, easy to extend, and communicates via the central controller.
The modular design enables multiple developers to work in parallel.

---

## ğŸš€ **Installation**

### 1. Clone the repository

```
git clone https://github.com/<your-username>/smart-vision-glasses
cd smart-vision-glasses
```

### 2. Create virtual environment

```
python -m venv venv
venv\Scripts\activate   # Windows
```

### 3. Install dependencies

```
pip install -r requirements.txt
```

---

## â–¶ï¸ **Run the Project**

```
python main.py
```

Then speak:

> **â€œHey Vision, turn on object detectionâ€**
> or
> **â€œHey Vision, open text readerâ€**

Press **Q** anytime to exit a mode.

---

## ğŸ“‚ **Project Structure**

```
smart_glasses/
â”‚â”€â”€ main.py
â”‚â”€â”€ mode_manager.py
â”‚â”€â”€ config/
â”‚â”€â”€ modes/
â”‚â”€â”€ utils/
â”‚â”€â”€ assets/
â”‚â”€â”€ models/
â”‚â”€â”€ logs/
â”‚â”€â”€ tests/
â”‚â”€â”€ requirements.txt
â”‚â”€â”€ README.md
```

---

## ğŸ§ª **Current Status (MVP)**

All primary features implemented and tested:

| Feature              | Status        |
| -------------------- | ------------- |
| Object Detection     | âœ… Working     |
| Text Reader (OCR)    | âœ… Working     |
| Face Recognition     | âœ… Working     |
| Emotion Detection    | âœ… Working     |
| GPS Mode             | âš ï¸ Prototype  |
| SOS Mode             | â³ Coming soon |
| Live Calling         | â³ Coming soon |
| Hardware Integration | â³ Planned     |

The prototype works reliably on a laptop and is already suitable for trials.

---

## ğŸ¯ **Impact**

This project aims to:

* Improve independence for visually impaired individuals
* Make assistive technology more **affordable**, **accessible**, and **offline-capable**
* Provide instant awareness of the environment
* Enable intelligent human-like interaction with surroundings
* Move towards a fully wearable pair of AI-powered smart glasses

This is more than a project â€” it is a step toward **inclusive, human-centered technology**.

---

## ğŸ›£ï¸ **Future Roadmap**

* ğŸ“± Android mobile application
* ğŸ”” Emergency SOS mode
* ğŸ“ Live caregiver calling
* ğŸ¥½ Wearable hardware (smart glasses)
* ğŸŒ™ Night vision with IR camera
* ğŸ—ºï¸ Full offline navigation
* ğŸ—£ï¸ On-device speech recognition (Vosk/DeepSpeech)

---

## ğŸ¤ **Contributing**

We welcome collaboration!
Please open an issue or pull request to contribute features, fixes, or ideas.

---

## ğŸ“œ **License**

This project is released under the **MIT License** â€” free to use, modify, and distribute.

---
